# -*- coding: utf-8 -*-
"""merge_sumários_classifica_competência_SBC_gera_habilidades.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E6k8eAWFS9yVu5fGcOwCMFCm2cqw5KsJ
"""
# ==============================================================================
# CLASSIFICA AS COMPETÊNCIAS QUANTO AO NÍVEL BLOOM (LEMBRAR, COMPREENDER,...)
# ==============================================================================
# --- 1. Instalar e Importar Bibliotecas ---
print("1. Instalando e importando bibliotecas...")
!pip install pandas openpyxl transformers accelerate bitsandbytes huggingface_hub -qqq

import pandas as pd
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig
from huggingface_hub import notebook_login, HfFolder
import os
from tqdm.notebook import tqdm
from google.colab import userdata

print("Bibliotecas prontas.")

# --- 2. Autenticação no Hugging Face ---
print("\n2. Autenticando no Hugging Face...")
try:
    hf_token = userdata.get('HF_TOKEN')
    print("Token do Hugging Face carregado via Secrets do Colab.")
except Exception:
    print("Token não encontrado no Secrets. Solicitando login interativo.")
    notebook_login()
    hf_token = HfFolder.get_token()

if not hf_token:
    raise ValueError("Falha na autenticação do Hugging Face.")
else:
    os.environ["HF_TOKEN"] = hf_token
    print("Autenticação concluída.")

# --- 3. Carregar Modelo LLM ---
print("\n3. Carregando modelo Llama 3.1...")
model_id = "meta-llama/Meta-Llama-3.1-8B-Instruct"

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    quantization_config=bnb_config,
    torch_dtype=torch.bfloat16,
    device_map="auto",
)

#Btemperatura baixa (quase zero) para respostas consistentes e factuais
classifier_pipeline = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=10, # A resposta é apenas uma palavra
    do_sample=True,
    temperature=0.1,
    top_p=0.9,
    return_full_text=False
)
print("Modelo Llama 3.1 carregado para classificação.")


# --- 4. Função para Inferir Nível de Bloom ---
NIVEIS_BLOOM = ["Lembrar", "Compreender", "Aplicar", "Analisar", "Avaliar", "Criar"]

def inferir_nivel_bloom(competencia_texto, llm_pipeline):
    """
    Usa o LLM para classificar uma competência em um dos 6 níveis de Bloom.
    """
    system_message = f"""
    Você é um especialista em pedagogia e na Taxonomia de Bloom.
    Sua tarefa é classificar uma competência educacional em um dos seis níveis da Taxonomia de Bloom.
    Os seis níveis são: {', '.join(NIVEIS_BLOOM)}.
    """
    user_message = f"""
    Analise a seguinte competência e retorne APENAS o nome do nível de Bloom correspondente, sem nenhuma explicação, pontuação ou texto adicional.

    Competência: "{competencia_texto}"
    Nível de Bloom:
    """
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message}
    ]

    try:
        output = llm_pipeline(messages)
        resultado = output[0]['generated_text'].strip()
        # Validação para garantir que a resposta é um dos níveis esperados
        for nivel in NIVEIS_BLOOM:
            if nivel.lower() in resultado.lower():
                return nivel
        print(f"  Aviso: Resposta inesperada do modelo para '{competencia_texto}': '{resultado}'. Retornando None.")
        return None
    except Exception as e:
        print(f"  Erro ao processar '{competencia_texto}': {e}")
        return None


# --- 5. Processamento Principal ---
print("\n5. Iniciando o processo de inferência de Nível de Bloom...")
input_filename = 'conteudos_completo_com_competencias.xlsx' # SEU ARQUIVO DE ENTRADA AQUI
output_filename = 'conteudos_com_bloom.xlsx'

try:
    # Tenta ler como Excel primeiro
    df = pd.read_excel(input_filename)
    print(f"Arquivo '{input_filename}' lido com sucesso como Excel.")
except Exception as e_excel:
    print(f"Não foi possível ler como Excel ({e_excel}), tentando ler como CSV separado por ponto e vírgula...")
    try:
        # Se falhar, tenta como CSV com separador ponto e vírgula
        df = pd.read_csv(input_filename, sep=';')
        print(f"Arquivo '{input_filename}' lido com sucesso como CSV.")
    except Exception as e_csv:
        raise ValueError(f"Não foi possível ler o arquivo de entrada como Excel ou CSV. Erro: {e_csv}")

# Garante que a coluna 'competencia_1' exista
if 'competencia_1' not in df.columns:
    raise ValueError("A coluna 'competencia_1' não foi encontrada no arquivo. Verifique o nome da coluna.")

# Pega todas as competências únicas para não reprocessar
competencias_unicas = df['competencia_1'].dropna().unique()
print(f"Encontradas {len(competencias_unicas)} competências únicas para classificar.")

# Dicionário para guardar os resultados (cache)
bloom_cache = {}

# Itera sobre as competências únicas com uma barra de progresso
for competencia in tqdm(competencias_unicas, desc="Classificando competências"):
    nivel_inferido = inferir_nivel_bloom(competencia, classifier_pipeline)
    bloom_cache[competencia] = nivel_inferido

# Mapeia os resultados de volta para o DataFrame original
print("\nMapeando os níveis de Bloom inferidos para a planilha...")
df['Nível_Bloom_Competência'] = df['competencia_1'].map(bloom_cache)

# Verifica se alguma competência não pôde ser classificada
nao_classificadas = df[df['Nível_Bloom_Competência'].isnull()]['competencia_1'].nunique()
if nao_classificadas > 0:
    print(f"Aviso: {nao_classificadas} competências não puderam ser classificadas.")

# --- 6. Salvar o Novo Arquivo ---
print(f"\n6. Salvando o novo arquivo com a coluna de Nível de Bloom...")
df.to_excel(output_filename, index=False)

print("\nProcesso concluído com sucesso!")
print(f"O novo arquivo '{output_filename}' foi gerado e está pronto para ser usado no próximo script.")
print("\nPré-visualização das colunas relevantes:")
print(df[['competencia_1', 'Nível_Bloom_Competência']].head(10))