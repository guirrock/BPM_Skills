# -*- coding: utf-8 -*-
"""merge_sumários_classifica_competência_SBC_gera_habilidades.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E6k8eAWFS9yVu5fGcOwCMFCm2cqw5KsJ
"""

# ==============================================================================
# SCRIPT ATRIBUIR SEÇÃO DO LIVRO A COMPETÊNCIA
# ==============================================================================
import pandas as pd
import spacy
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# --- 1. Carregar o arquivo com as subseções deduplicadas ---
try:
    df_groups = pd.read_excel("Final_BPM_Books_Definitivo.xlsx")
except FileNotFoundError:
    print("Erro: O arquivo 'Final_BPM_Books.xlsx' não foi encontrado.")
    exit()

# --- 2. Obter apenas os títulos únicos das seções ---
print("Extraindo os títulos únicos das seções ('group_name')...")
unique_group_names = df_groups['group_name'].unique()
df_sections = pd.DataFrame({'group_name': unique_group_names})

num_secoes_unicas = len(df_sections)
print(f"Análise será feita em {num_secoes_unicas} títulos de seção únicos.")


# --- 3. Definir Competências ---
competencias = {
    "Modelar processos de negócio":"Modelar processos de negócio",
    "Analisar processos de negócio":"Analisar processos de negócio",
    "Projetar processos de negócio":"Projetar processos de negócio",
    "Implementar processos de negócio":"Implementar processos de negócio"
}
competencia_nomes_ordenados = list(competencias.keys())

# --- 4. Pré-processamento do TÍTULO da seção ---
try:
    nlp = spacy.load("pt_core_news_sm")
except:
    from spacy.cli import download
    download("pt_core_news_sm")
    nlp = spacy.load("pt_core_news_sm")

def preprocess_text(text):
    if not isinstance(text, str): return ""
    doc = nlp(text.lower())
    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and not token.is_space]
    return " ".join(tokens)

df_sections['title_clean'] = df_sections['group_name'].apply(preprocess_text)
competencias_pre_processadas = {name: preprocess_text(desc) for name, desc in competencias.items()}

# --- 5. Gerar Embeddings a partir dos TÍTULOS ---
print("Gerando embeddings para os TÍTULOS das seções e competências...")
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# Criamos os embeddings a partir dos títulos limpos
section_embeddings = model.encode(df_sections['title_clean'].tolist())
competencias_embeddings = model.encode(list(competencias_pre_processadas.values()))

# --- 6. Calcular similaridades ---
results = []
print("Calculando similaridades e atribuindo competências...")

for i, row in df_sections.iterrows():
    sims = cosine_similarity(section_embeddings[i].reshape(1, -1), competencias_embeddings)[0]
    sorted_indices = np.argsort(sims)[::-1]

    first_idx = sorted_indices[0]
    second_idx = sorted_indices[1] if len(sorted_indices) > 1 else None

    results.append({
        'group_name': row['group_name'],
        'competencia_1': competencia_nomes_ordenados[first_idx],
        'similaridade_1': sims[first_idx],
        'competencia_2': competencia_nomes_ordenados[second_idx] if second_idx is not None else None,
        'similaridade_2': sims[second_idx] if second_idx is not None else None
    })

df_results = pd.DataFrame(results)

# --- 7. Salvar em Excel ---
output_filename = "Grupos_vs_Competencias.xlsx"
df_results.to_excel(output_filename, index=False)
print(f"\nPlanilha '{output_filename}' gerada com sucesso!")
print("Cada linha neste arquivo representa um TÍTULO de seção ('group_name') e suas competências.")