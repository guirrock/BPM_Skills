# -*- coding: utf-8 -*-
"""merge_sumários_classifica_competência_SBC_gera_habilidades.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E6k8eAWFS9yVu5fGcOwCMFCm2cqw5KsJ
"""
# ==============================================================================
# SCRIPT GERAÇÃO DE HABILIDADES PARA AS COMPETÊNCIAS
# ==============================================================================
# --- 1. Instalar e Importar Bibliotecas ---
print("1. Instalando e importando bibliotecas...")
!pip install pandas openpyxl transformers accelerate bitsandbytes huggingface_hub sentence-transformers -qqq

import pandas as pd
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig
from huggingface_hub import notebook_login, HfFolder
import re
import os
from tqdm.notebook import tqdm
from google.colab import userdata
from sentence_transformers import SentenceTransformer, util

print("Bibliotecas prontas.")

# --- 2. Autenticação no Hugging Face ---
print("\n2. Autenticando no Hugging Face...")
try:
    hf_token = userdata.get('HF_TOKEN')
    print("Token do Hugging Face carregado via Secrets do Colab.")
except Exception:
    print("Token não encontrado no Secrets. Solicitando login interativo.")
    notebook_login()
    hf_token = HfFolder.get_token()

if not hf_token:
    raise ValueError("Falha na autenticação do Hugging Face.")
else:
    os.environ["HF_TOKEN"] = hf_token
    print("Autenticação concluída.")

# --- 3. Carregar Dados do Excel ---
print("\n3. Carregando dados do Excel...")
file_path_input = 'conteudos_com_bloom.xlsx'
if not os.path.exists(file_path_input):
    raise FileNotFoundError(f"Arquivo '{file_path_input}' não encontrado. Certifique-se de executar o script de inferência de Bloom primeiro.")

df_conteudos = pd.read_excel(file_path_input)
# Renomeia colunas para garantir compatibilidade
df_conteudos.rename(columns={
    "competencia_1": "Competência",
    "final_title": "conteudo_curso",
    "Tipo_Conhecimento_Inferido": "Tipo_Mais_Frequente",
    # A coluna 'group_name' será usada diretamente, sem renomear para 'categoria_referencia' para evitar confusão.
}, inplace=True, errors='ignore')
print("Dados carregados.")

# --- 4. Carregar Modelos (LLM e SentenceTransformer) ---
print("\n4. Carregando modelos...")
model_id = "meta-llama/Meta-Llama-3.1-8B-Instruct"

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True, bnb_4bit_quant_type="nf4", bnb_4bit_compute_dtype=torch.bfloat16
)

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id, quantization_config=bnb_config, torch_dtype=torch.bfloat16, device_map="auto"
)

generator_pipeline = pipeline(
    "text-generation", model=model, tokenizer=tokenizer, max_new_tokens=400,
    do_sample=True, temperature=0.3, top_p=0.9, return_full_text=False
)
print("Modelo Llama 3.1 carregado.")

embedding_model = SentenceTransformer('distiluse-base-multilingual-cased-v1')
print("Modelo SentenceTransformer carregado.")

# --- 5. Funções de Apoio e Geração de Objetivos ---

BLOOM_HIERARCHY = {
    "Lembrar": 1, "Compreender": 2, "Aplicar": 3,
    "Analisar": 4, "Avaliar": 5, "Criar": 6
}

def selecionar_conteudos_diversos(conteudos_list, embedding_model, similarity_threshold=0.7):
    if not conteudos_list: return []
    conteudos_list = [str(c) for c in conteudos_list if pd.notna(c)]
    if not conteudos_list: return []
    embeddings = embedding_model.encode(conteudos_list, convert_to_tensor=True)
    selected_contents = []
    processed_indices = set()
    for i in range(len(conteudos_list)):
        if i in processed_indices: continue
        similar_indices = {i}
        for j in range(i + 1, len(conteudos_list)):
            if j in processed_indices: continue
            if util.cos_sim(embeddings[i], embeddings[j]).item() >= similarity_threshold:
                similar_indices.add(j)
        best_content_in_group = max((conteudos_list[idx] for idx in similar_indices), key=len)
        selected_contents.append(best_content_in_group)
        processed_indices.update(similar_indices)
    return selected_contents

def calcular_numero_ideal_objetivos(n_conteudos_competencia_diversos, n_dimensoes_competencia, n_grupos_competencia, nivel_bloom):
    base_obj = min(8, max(3, n_conteudos_competencia_diversos // 10))
    if n_dimensoes_competencia > 1: base_obj += 1
    if n_grupos_competencia > 1: base_obj += 1
    nivel_bloom_valor = BLOOM_HIERARCHY.get(nivel_bloom, 1)
    if nivel_bloom_valor <= 2: base_obj = max(3, base_obj - 1)
    if nivel_bloom_valor == 3: base_obj = min(8, base_obj)
    if nivel_bloom_valor == 4: base_obj = min(8, base_obj + 1)
    if nivel_bloom_valor > 4: base_obj = min(8, base_obj + 2)
    return max(3, min(8, base_obj))

def gerar_objetivos_com_prompt_refinado(
    competencia, nivel_bloom_competencia,
    conteudos_selecionados,
    llm_pipeline,
    max_objetivos
):
    conteudos_para_prompt_str = "\n- ".join(conteudos_selecionados)
    system_message = "Você é um especialista em design instrucional e na Taxonomia de Bloom."
    user_message = f"""
    A Competência Alvo é: "{competencia}"
    O Nível de Complexidade Cognitiva (Bloom) desta competência é: "{nivel_bloom_competencia}"

    Conteúdos de Referência:
    - {conteudos_para_prompt_str}

    Sua Tarefa Principal:
    Analise a lista de 'Conteúdos de Referência' acima. Usando APENAS os conteúdos que possuem uma conexão direta e clara com a 'Competência Alvo', crie exatamente {max_objetivos} habilidades intermediárias que um aluno precisa desenvolver para alcançar a competência.

    Regras Importantes:
    1. **Foco na Relevância:** Sua primeira e mais importante tarefa é FILTRAR. Se um conteúdo não parece pertencer à competência, **NÃO o utilize**. É melhor gerar uma habilidade mais geral baseada nos conteúdos relevantes do que forçar uma conexão inexistente.
    2. **Ação e Complexidade:** Cada habilidade deve começar com um verbo de ação no infinitivo (ex: "Explicar", "Aplicar") e respeitar o nível de complexidade máximo "{nivel_bloom_competencia}" ou inferior.
    3. **Formato da Saída:** Liste APENAS as habilidades geradas, uma por linha, sem introduções ou conclusões.
    """
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message}
    ]
    try:
        output = llm_pipeline(messages)
        generated_text = output[0]['generated_text'].strip()
        objetivos = [
            re.sub(r'^[-\*\d\.\s]*', '', linha).strip()
            for linha in generated_text.split('\n')
            if len(linha.strip().split()) > 2
        ]
        seen = set()
        unique_objectives = []
        for obj in objetivos:
            if obj.lower() not in seen:
                unique_objectives.append(obj)
                seen.add(obj.lower())
        return unique_objectives
    except Exception as e:
        print(f"  Aviso: Erro na geração do LLM para a competência '{competencia}': {e}")
        return [f"ERRO: {e}"]

# --- 6. Processar e Gerar Objetivos para Cada Competência ---
print("\n6. Processando cada competência...")
resultados_objetivos = []
grouped_by_competence = df_conteudos.groupby(["Competência", "Nível_Bloom_Competência"])

for (competencia, nivel_bloom_competencia), group in tqdm(grouped_by_competence, desc="Gerando objetivos"):
    if pd.isna(competencia) or pd.isna(nivel_bloom_competencia):
        continue

    todos_conteudos_da_competencia = group['conteudo_curso'].dropna().tolist()
    if not todos_conteudos_da_competencia:
        continue

    conteudos_diversos = selecionar_conteudos_diversos(todos_conteudos_da_competencia, embedding_model)
    n_conteudos_diversos = len(conteudos_diversos)

    n_dimensoes = group['Tipo_Mais_Frequente'].nunique()

     # Verifica de forma segura se a coluna de agrupamento de categorias existe
    if 'group_name' in group.columns:
        n_grupos = group['group_name'].nunique()
    else:
        print("  Aviso: A coluna 'group_name' não foi encontrada para a heurística. Usando n_grupos=1 como padrão.")
        n_grupos = 1 # Valor padrão seguro que permite a execução

    n_objetivos_ideais = calcular_numero_ideal_objetivos(
        n_conteudos_competencia_diversos=n_conteudos_diversos,
        n_dimensoes_competencia=n_dimensoes,
        n_grupos_competencia=n_grupos,
        nivel_bloom=nivel_bloom_competencia
    )

    print(f"\nProcessando: '{competencia}' (Nível: {nivel_bloom_competencia})")
    print(f"  > Número ideal de habilidades calculado pela heurística: {n_objetivos_ideais}")

    objetivos_gerados = gerar_objetivos_com_prompt_refinado(
        competencia=competencia,
        nivel_bloom_competencia=nivel_bloom_competencia,
        conteudos_selecionados=conteudos_diversos,
        llm_pipeline=generator_pipeline,
        max_objetivos=n_objetivos_ideais
    )

    resultados_objetivos.append({
        'Competência': competencia,
        'Nível_Bloom_Competência': nivel_bloom_competencia,
        'Num_Objetivos_Ideal_Calculado': n_objetivos_ideais,
        'Objetivos_Gerados': "\n".join(objetivos_gerados)
    })

df_objetivos_finais = pd.DataFrame(resultados_objetivos)

# --- 7. Salvar os Resultados ---
print("\n7. Salvando resultados...")
output_file = 'objetivos_de_aprendizagem_final.xlsx'
df_objetivos_finais.to_excel(output_file, index=False)
print(f"Processo concluído! Objetivos salvos em '{output_file}'.")
print("\nPré-visualização do resultado:")
print(df_objetivos_finais.head())